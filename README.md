# Purple


domain-specific transferrable intelligence

live free models

purple contradictions amongst cohesion and cohisive. individual and society. want and need. 

# Intelligence

It's obvious that "*defining intelligence*" can play a critical role in "*creating intelligence*." How are we going to define intelligence? That's another story.

There are various domains in which we can [define intelligence](https://en.wikipedia.org/wiki/Intelligence): emotional, social, street smart, etc. Also, there’s the famous Turing test to recognize artificial intelligence. But which of these many definitions of intelligence can help us describe the "*sense of intelligence*"? Things that make us call some behavior intelligent when we see it. This is one of the topics I've been curious about for quite a time. My ideas to define intelligence, form around three main concepts:

**Concept 1.** Our intelligence is limited to a "**domain-set**": meaning we can't apply the same amount of intelligence to everything in life. Someone is maybe very good with her muscle memory in playing the piano but not very sharp in understanding chemistry or even not as good with another instrument like a guitar. Even a high IQ person may be very good at science but cannot perform the best surgery while being a Nobel prize-winning physicist. A "domain-set" is a term I use to identify the set of domains that we consider someone intelligent at.

**Concept 2. Physics, live, dynamic**: An intelligent person has the ability to make sense of symbols in a math formula and see the end result, recognize the dynamics of a game, understand how to be good at some sport, etc. In any domain-set, there's ruling physic of how things are connected to each other and how we can exploit them to our benefit.

**Concept 3.** Intelligence can be **learned**: When an intelligent person finds the physics of a domain-set and exploits it to her benefit, we learn from them.

With these concept definitions, we'll go to the next section about two ideas: "Subjective intelligence" and "Artificial Curiosity". I will also mention how these ideas, concepts, and definitions are related to ideas from DeepMind papers.

One human can be supersmart still won't do much on earth, but a collection of humans plus time, will be change the world.

Stories and embeddinga can be used to communicate between livings.

It should be live not waiting for our prompt 

the problem with agent-riented, collective intelligence etc is that they neglect the value of one small idea. and but that’s actually how humanity works

What works is systematic intelligence.

The creative intelligence is unique to humans

Philosophy is not implemented in machines

A qualitative test: when a system autonomously and independently came to conclusion to build another system to delegate computation, that’s intelligence

Marvec paradox

What intelligence are we building ? Dumb, normal, intelligent 

## Subjective intelligence

If we assume C1 and C2 are correct, in every situation, an intelligent system knows the winning function. There's no general way of learning everything. In any "domain-set", there's a ruling physics, the system exploits that physic to its advantage (the scary part of AGI).

This also shows if the system cannot figure out the physics, it can not understand it (just like us humans).

But if we scale the system to a point that can model complex huge "domain sets", it can find a way to travel to new galaxies, or how solve the climate crisis?

If intelligence is to find patterns and turn the dynamics into a game, how can we build a system that can do that?

1. Ultimate game results are not defined by the system (winning is obvious and clear: a car that moves from one place to another, a game to win, a successful trade), so if there's not a winning definition, the task is harder, subjective and is not a good example of a generic intelligence
2. genius works, like understanding the secrets of the universe are things that can be resolved, traveling to far galaxies, etc. they are questions that should be entered to this machine, that machine provides us the answer, we don't understand it, but we can use it
3. (not necessarily related to this idea: we may don't need big memories for AGI, if people see a number keypad they memorize numbers better, so we don't memorize because we don't need it. Laziness is important for intelligence. Also, pain→we use pain to find our way. We constantly minimize pain. maybe this is a key to building the AGI)

difference between average agents and genius agents

## Artificial curiosity

If you don't see unexpected behavior, there's no curiosity, And if curiosity is important for intelligence, then there's no intelligence. Our intelligence is collective. Curiosity in communication turns into being noisy; if there's a collective model with no amount of being noisy, there's no curiosity

- [DeepMind's latest research at ICLR 2022](https://www.deepmind.com/blog/deepminds-latest-research-at-iclr-2022)
- [2022 Conference](https://iclr.cc/)
- [When should agents explore? | OpenReview](https://openreview.net/forum?id=dEwfxt14bca)
- [https://openreview.net/pdf?id=dEwfxt14bca](https://openreview.net/pdf?id=dEwfxt14bca)
- [Learning more skills through optimistic exploration | OpenReview](https://openreview.net/forum?id=cU8rknuhxc)
- [https://openreview.net/pdf?id=cU8rknuhxc](https://openreview.net/pdf?id=cU8rknuhxc)
- [Defending Against Image Corruptions Through Adversarial Augmentations | OpenReview](https://openreview.net/forum?id=jJOjjiZHy3h)
- [https://openreview.net/pdf?id=jJOjjiZHy3h](https://openreview.net/pdf?id=jJOjjiZHy3h)

[https://openreview.net/pdf?id=b-ny3x071E5](https://openreview.net/pdf?id=b-ny3x071E5)

2022: Deepmind releases paper on bootstrapped meta-learning and scaling RL agents 2023: RL agent trained for multi-task learning solves the majority of perfect information games. It's a scaled-up decision transformer. Scaling laws for RL agents are discovered, similar to language models. 2024: Large scale RL agents are combined with frozen vision and language models via cross-attention, can be prompted one-shot with language/vision tokens to solve novel tasks. 2025: RL agents enter the real world - first pre-trained in diverse synthetic environments, then via imitation learning from youtube videos, and finally in an online fashion via real-time human interaction

Yann lecun model

[https://openreview.net/pdf?id=BZ5a1r-kVsf](https://openreview.net/pdf?id=BZ5a1r-kVsf)

[https://www.youtube.com/watch?v=DokLw1tILlw](https://www.youtube.com/watch?v=DokLw1tILlw)

I think we don't put enough research on this part and we jump too fast to implement intelligence. This is how actually business world works: Implement what works, do things that don't scale, etc. then we'll figure out where to go after that.

Now that we've [built big models](https://arxiv.org/pdf/2203.15556.pdf), and we're lining up GPU racks can also be a good opportunity to look for other ways too.

- --

staying alive, minimize pain, boredom, laziness

smart people see some patterns and connections to exploit. many of the hard problems get solved this way. a way of designing intelligence. and on the side it raises a question that are these connections these people make related to their brain structure? are the connection that people with high eq make related to their brian?

We don't just need AI, we also need explainability

[https://www.linkedin.com/posts/yann-lecun_ai-activity-6932436820454502400-hV39/?utm_source=linkedin_share&utm_medium=android_app](https://www.linkedin.com/posts/yann-lecun_ai-activity-6932436820454502400-hV39/?utm_source=linkedin_share&utm_medium=android_app)

ai can beat us all

[https://www.cold-takes.com/ai-could-defeat-all-of-us-combined](https://www.cold-takes.com/ai-could-defeat-all-of-us-combined)

- ****Common Sense Comes Closer to Computers****
    - [https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/](https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/)
    - 
- ------

As a researcher in the field, I don't find definitions like "adaptive behavior" suitable for what we mean by intelligence.

(In reinforcement learning, we define intelligence as getting more rewards.)Using activation functions to build models that can imitate learning through gradient descent. A very practical way but we still don't have AGI.

[*Despite observing intelligence among other species, the way I see intelligence works amongst us humans is 1) a combination of different abilities and behaviors and 2) certainly not the ability to drive, eat, etc ..*]

+++ key

Stories aren’t real, and yet they’re meaningful: how we create mental paths between two abstract concepts and later on use them for other concepts

**Imagination in the AGI**

we need a little bad memory

[https://twitter.com/nabeelqu/status/1610267023694770179?s=20&t=x27uXfUd6zlQLPL3a4nH7g](https://twitter.com/nabeelqu/status/1610267023694770179?s=20&t=x27uXfUd6zlQLPL3a4nH7g)

Better understanding intelligence
[https://kirkegaard.substack.com/p/iq-can-be-increased-by-more-education](https://kirkegaard.substack.com/p/iq-can-be-increased-by-more-education)




[Collective intelligence - Wikipedia](https://en.wikipedia.org/wiki/Collective_intelligence#:~:text=Collective%20intelligence%20(CI)%20is%20shared,appears%20in%20consensus%20decision%20making.)

[Yann LeCun on a vision to make AI systems learn and reason like animals and humans](https://ai.facebook.com/blog/yann-lecun-advances-in-ai-research/)

[Meta AI | Facebook](https://www.facebook.com/MetaAI/)

[Shaped](https://www.shaped.ai/blog/yann-lecun-a-path-towards-autonomous-machine-intelligence)

[Yann LeCun's Paper on creating autonomous machines](https://datasciencelearningcenter.substack.com/p/yann-lecuns-paper-on-creating-autonomous)

[pdf](https://openreview.net/pdf?id=BZ5a1r-kVsf)
 


# Visionary papers
Turing test is not complete: an AGI should not talk like a normal person, but the most intelligent perosn we’ve ever seen. 

importance of vision papers

[https://scienceplusplus.org/visions/index.html](https://scienceplusplus.org/visions/index.html)

I think the key for a better AI is to model the way learn and represent things not the structure of our brain

How each person builds its understanding and starts to generalize

my intuition → deepmind work → prediction


# Alternative to Turing test
Either we use LFM or not, I propose that we can call something AGI not when it's indistinguishable from a human in conversation but when it can design another AGI

# Personal Motivation Story
For me, beside the Asimov novels and years of working on AI projects, this specific work started on Novemeber 2021 as thread of thoughts and ideas where I did initial research and try to come up with a model that can address AGI on November 2021. At the time our data team at [Eveince](https://eveince.com) was working graph neural networks to build a better represntation of text data and relation of concepts for understanding textual financial comments [here](https://arxiv.org/abs/2211.16103).

AGI might be defined as something that can pass the Turing test but with recent progress most researchers are re-thinking that[^1]. 

On Apr 25th [2022] to Fri the 29th, was the ICLR 2022, one of the most important events of introducing cutting-edge achievements in AI, sponsored by DeepMind, Google Research, Two Sigma, Microsoft, Meta, etc. DeepMind published an overview of their papers this year in ([this post](https://www.deepmind.com/blog/deepminds-latest-research-at-iclr-2022)).


In the past couple of months, I came up with ideas based on my intuitions and research, which I found similar in some senses to what DeepMind has published recently. This convergence of ideas toward creating a better AI/AGI, especially in the "[BOOTSTRAPPED META-LEARNING](https://openreview.net/pdf?id=b-ny3x071E5)" was exciting. I found this excitement as an opportunity to articulate these ideas as a basis for more research. Although the Gato and DALL-E are at the center of attention, these ideas are not in the direction of Gato or DALL-E.

[^1]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6776890/
