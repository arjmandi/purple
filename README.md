# Purple
A vision paper, outlining a model to implement AGI.

# Intelligence

It's clear that "*defining intelligence*" can play a critical role in "*creating intelligence*." How can we define intelligence? 

There are various domains in which we can [define intelligence](https://en.wikipedia.org/wiki/Intelligence): emotional, social, street smart, etc. 

We can also refer to the famous Turing test to define (artificial) intelligence, but with the recent language models we may build a system that can be indistinguishable from human when we chat with it.
[openai and deepmind definitions of intelligence] 

I point out another aspect of the Turing test that is not related to the AI system but to the person that interacts with it.

Alan Turing used conversation and language as an interface
which of these many definitions of intelligence can help us describe the "*sense of intelligence*"? Things that make us call some behavior intelligent when we see it. This is one of the topics I've been curious about for quite a time. 


My ideas to define intelligence, form around three main concepts:

**Concept 1.** Our intelligence is limited to a "**domain-set**": meaning we can't apply the same amount of intelligence to everything in life. Someone is maybe very good with her muscle memory in playing the piano but not very sharp in understanding chemistry or even not as good with another instrument like a guitar. Even a high IQ person may be very good at science but cannot perform the best surgery while being a Nobel prize-winning physicist. A "domain-set" is a term I use to identify the set of domains that we consider someone intelligent at.

**Concept 2. Physics, live, dynamic**: An intelligent person has the ability to make sense of symbols in a math formula and see the end result, recognize the dynamics of a game, understand how to be good at some sport, etc. In any domain-set, there's ruling physic of how things are connected to each other and how we can exploit them to our benefit.

**Concept 3.** Intelligence can be **learned**: When an intelligent person finds the physics of a domain-set and exploits it to her benefit, we learn from them.

With these concept definitions, we'll go to the next section about two ideas: "Subjective intelligence" and "Artificial Curiosity". I will also mention how these ideas, concepts, and definitions are related to ideas from DeepMind papers.

One human can be supersmart still won't do much on earth, but a collection of humans plus time, will be change the world.

Stories and embeddinga can be used to communicate between livings.

It should be live not waiting for our prompt 

the problem with agent-riented, collective intelligence etc is that they neglect the value of one small idea. and but that’s actually how humanity works

What works is systematic intelligence.

The creative intelligence is unique to humans

Philosophy is not implemented in machines

A qualitative test: when a system autonomously and independently came to conclusion to build another system to delegate computation, that’s intelligence

Marvec paradox

What intelligence are we building ? Dumb, normal, intelligent 

## Live Free Models

## The name, Purple
Purple contradictions amongst cohesion and cohisive. individual and society. want and need. 


## Subjective intelligence

If we assume C1 and C2 are correct, in every situation, an intelligent system knows the winning function. There's no general way of learning everything. In any "domain-set", there's ruling physics, the system exploits that physic to its advantage (the scary part of AGI).

This also shows if the system can not figure out the physics, it can not understand it (just like us humans).

But if we scale the system to a point that can model complex huge "domain sets", it can find a way to travel to new galaxies, or how solve the climate crisis?

If intelligence is, to find patterns and turn the dynamics into a game, how can we build a system that can do that?

1. Ultimate game results are not defined by the system (winning is obvious and clear: a car that moves from one place to another, a game to win, a successful trade), so if there's not a winning definition, the task is harder, subjective and is not a good example of a generic intelligence
2. genius works, like understanding the secrets of the universe are things that can be resolved, traveling to far galaxies, etc. they are questions that should be entered to this machine, that machine provides us the answer, we don't understand it, but we can use it
3. (not necessarily related to this idea: we may don't need big memories for AGI, if people see a number keypad they memorize numbers better, so we don't memorize because we don't need it. Laziness is important for intelligence. Also, pain→we use pain to find our way. We constantly minimize pain. maybe this is a key to building the AGI)



## Artificial curiosity

If you don't see unexpected behavior, there's no curiosity, And if curiosity is important for intelligence, then no unexpected behavior means there's no intelligence. Our intelligence is collective. Curiosity in communication turns into being noisy; if there's a collective model with no amount of being noisy, there's no curiosity

- [DeepMind's latest research at ICLR 2022](https://www.deepmind.com/blog/deepminds-latest-research-at-iclr-2022)
- [2022 Conference](https://iclr.cc/)
- [When should agents explore? | OpenReview](https://openreview.net/forum?id=dEwfxt14bca)
- [https://openreview.net/pdf?id=dEwfxt14bca](https://openreview.net/pdf?id=dEwfxt14bca)
- [Learning more skills through optimistic exploration | OpenReview](https://openreview.net/forum?id=cU8rknuhxc)
- [https://openreview.net/pdf?id=cU8rknuhxc](https://openreview.net/pdf?id=cU8rknuhxc)
- [Defending Against Image Corruptions Through Adversarial Augmentations | OpenReview](https://openreview.net/forum?id=jJOjjiZHy3h)
- [https://openreview.net/pdf?id=jJOjjiZHy3h](https://openreview.net/pdf?id=jJOjjiZHy3h)





Yann lecun model

[https://openreview.net/pdf?id=BZ5a1r-kVsf](https://openreview.net/pdf?id=BZ5a1r-kVsf)

[https://www.youtube.com/watch?v=DokLw1tILlw](https://www.youtube.com/watch?v=DokLw1tILlw)


Now that we've[built big models](https://arxiv.org/pdf/2203.15556.pdf), and we're lining up GPU racks can also be a good opportunity to look for other ways too.

- --



smart people see some patterns and connections to exploit. many of the hard problems get solved this way. a way of designing intelligence. and on the side it raises a question that are these connections these people make related to their brain structure? are the connection that people with high eq make related to their brian?



[https://www.linkedin.com/posts/yann-lecun_ai-activity-6932436820454502400-hV39/?utm_source=linkedin_share&utm_medium=android_app](https://www.linkedin.com/posts/yann-lecun_ai-activity-6932436820454502400-hV39/?utm_source=linkedin_share&utm_medium=android_app)




[https://www.cold-takes.com/ai-could-defeat-all-of-us-combined](https://www.cold-takes.com/ai-could-defeat-all-of-us-combined)

- ****Common Sense Comes Closer to Computers****
 [https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/](https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/)

- ------

As a researcher in the field, I don't find definitions like "adaptive behavior" suitable for what we mean by intelligence.

(In reinforcement learning, we define intelligence as getting more rewards.)Using activation functions to build models that can imitate learning through gradient descent. A very practical way but we still don't have AGI.

[*Despite observing intelligence among other species, the way I see intelligence works amongst us humans is 1) a combination of different abilities and behaviors and 2) certainly not the ability to drive, eat, etc ..*]


[https://twitter.com/nabeelqu/status/1610267023694770179?s=20&t=x27uXfUd6zlQLPL3a4nH7g](https://twitter.com/nabeelqu/status/1610267023694770179?s=20&t=x27uXfUd6zlQLPL3a4nH7g)

Better understanding intelligence
[https://kirkegaard.substack.com/p/iq-can-be-increased-by-more-education](https://kirkegaard.substack.com/p/iq-can-be-increased-by-more-education)


[Collective intelligence - Wikipedia](https://en.wikipedia.org/wiki/Collective_intelligence#:~:text=Collective%20intelligence%20(CI)%20is%20shared,appears%20in%20consensus%20decision%20making.)


[Yann LeCun on a vision to make AI systems learn and reason like animals and humans](https://ai.facebook.com/blog/yann-lecun-advances-in-ai-research/)


[Shaped](https://www.shaped.ai/blog/yann-lecun-a-path-towards-autonomous-machine-intelligence)

[Yann LeCun's Paper on creating autonomous machines](https://datasciencelearningcenter.substack.com/p/yann-lecuns-paper-on-creating-autonomous)

[pdf](https://openreview.net/pdf?id=BZ5a1r-kVsf)

# Explainability
Designing AGI is by itself hard and embedding explainability from the beginning makes it less practical.
The fact that we humans, as a benchmark of intelligence,  struggle to explain why we do something is the core of the unnecessary complexity. 
The non-deterministic nature if our decision-making process is a key for intelligence. (e.g. Even most sophisticated humans might do unreasonable things) So I will exclude explainability from this research and propose to use control mechanisms that help us stay safe rather than having a white-boxed analysis of AI decision making.
 
# Open Topics
1. Staying alive: should the model show a will to live?
2. Minimize pain: everything we do can be modeled as pain minimizing. is this an angle that helps the design?
3. Boredom and laziness: should the model show boredom and laziness?
4. Difference between average agents and genius agents
5. I believe the key for a better AI is to model the way learn and represent things not the structure of our brain
How each person builds its understanding and starts to generalize
6.Stories aren’t real, and yet they’re meaningful: how we create mental paths between two abstract concepts and later on use them for other concepts
7.we need a little bad memory, forgetting 
8. Imagination in the AGI


# Vision papers
What is a vision paper?

[https://scienceplusplus.org/visions/index.html](https://scienceplusplus.org/visions/index.html)


# Goal: An alternative to the Turing test
If I don't set a tangible goal, this project will be either too ambitious or become saturated too early. There's a need to define the final goal.

My definition of AGI is not when it's indistinguishable from a human in conversation but when it can design another AGI. This definition seems so simple that I believe somebody else has thought about it before me. So in that case, I too give my vote to this definition of AGI.

# Personal Motivation Story
The Motivation of this work, beside the Asimov novels and years of working on AI projects, started in October 2021. 
AI has always been a part of my professional career, but it was the first conversation topic that I had with the person I love. 

In October 2021 something terrible happened, and it made something inside me to flip. I wasn't aware of it, but that event made me work on AI more than before in my free time, unconsciously. Months later, I noticed it in myself. I was thinking that if I create AI, that first conversation will be restored and love will find its way to me.


It might seem cool to work on AGI, but it was also mad and unrealistic, starting from nothing and from nowhere. At that period, our data team at [Eveince](https://eveince.com) was working on graph neural networks to build a better representation of texts for better understanding of financial advice given by experts on the internet [here](https://arxiv.org/abs/2211.16103). and I was reading about and thinking about graphs networks. But then I came to the conclusion that graphs inherently and generally are not a good tool to represent behaviour when they represent data and vice versa [On the Edge #5](https://arjmandi.substack.com/p/on-the-edge-5). 

This wasn't a step toward a design, rather a step toward removing designs that don't work. This led me to read more and search more where I found almost all of the available network architectures empty of characteristics I was looking for but then again small lights in the path like [this tweet](https://twitter.com/ylecun/status/1492604977260412928) from LeCunn kept me going. Studying Deepmind and OpenAI works has also made me draw some predictions over the next months, not to feel good about my predictions but to see if I was right and current architectures are not what I'm looking for, this might help me to find the design.  [On the Edge #11](https://arjmandi.substack.com/p/on-the-edge-11). 


On April 25th 2022, the ICLR 2022 was held. One of the most important events of introducing cutting-edge achievements in AI, sponsored by DeepMind, Google Research, Two Sigma, Microsoft, Meta, etc. DeepMind published an overview of their papers for ICLR in [this post](https://www.deepmind.com/blog/deepminds-latest-research-at-iclr-2022). And I started to see a convergence between my findings and what was reflected in the "[BOOTSTRAPPED META-LEARNING](https://openreview.net/pdf?id=b-ny3x071E5)". 

I articulated my ideas as a basis for more research even though interesting works at the time like Gato and DALL-E were on a different path. They've progressed dramatically over the past year into new versions or models like PALM-E. I categorize them as new computation tools, and for AGI I took another direction which has been depicted here as Purple.
